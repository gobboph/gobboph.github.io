<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Roberto Gobbetti</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2016-11-12T18:30:00-05:00</updated><entry><title>Don't shoot the messenger!</title><link href="/blog/election_2016/" rel="alternate"></link><updated>2016-11-12T18:30:00-05:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2016-11-12:blog/election_2016/</id><summary type="html">&lt;p&gt;Despite living in the States on and off for seven years and witnessing the 2012 presidential election, this year I got caught into the campaign madness. I felt the stakes were higher than usual: I had moved back to New York City with the prospect of building a family here but, most importantly, the circus around the election and its rules are truly entertaining for an outsider.&lt;/p&gt;
&lt;p&gt;I am a data geek, and like many of my kind, I became addicted to following how the election predictive models developed throughout the past few months. That is why I am so appalled by the anger so many people seem to direct towards the modelers now that the election is over.&lt;/p&gt;
&lt;p&gt;Articles have been published, even &lt;a href="http://www.nytimes.com/2016/11/10/technology/the-data-said-clinton-would-win-why-you-shouldnt-have-believed-it.html"&gt;in the New York Times&lt;/a&gt;, blasting the models and their makers for not correctly predicting the outcome of the election. These voices seem to confuse a risk model for a deterministic one. The former is what we saw on sites like FiveThirtyEight or even the Times itself, while the second would always give the same outcome given the same initial conditions.&lt;/p&gt;
&lt;p&gt;Let me make this clear with an example. Let’s suppose I play a game of Russian roulette with one bullet, then my probability of survival is about 83%. This is based on the assumption that there are 6 equally probable scenarios and only one kills me. From a frequentist perspective, this means that if 100 people were to play the same game of Russian roulette, around 17 of them would die. If I play it only once and I kill myself, it would be foolish to say that the probability computation was wrong: I was just one of those 17 out of 100.&lt;/p&gt;
&lt;p&gt;This is to say two things: first that it is hard to judge the quality of a model on a single experiment (and we have just one election in 2016). Second, that if someone gives an 80% chance to an event and you take the event for granted, you are making a mistake, not the modeler.&lt;/p&gt;
&lt;p&gt;One sees now that the wild criticism certain models have received might be misplaced. Nate Silver’s FiveThirtyEight model gave something around 70% chance to a Clinton win, with a sizable probability (~12%) of her winning the popular vote despite losing the electoral college. These probabilities are far from being inconceivable.&lt;/p&gt;
&lt;p&gt;If one wants to judge the goodness of FiveThirtyEight’s model, then perhaps they should look at how it did state by state: it predicted most of the swing states within a reasonable error (which was admittedly large this year). Moreover, it predicted Clinton would win the popular vote by ~3%, which turned out to be pretty close to reality.&lt;/p&gt;
&lt;p&gt;I did not look as deeply into the details of the Times’ model, but in the days before the election, it gave Clinton a winning probability of 85%, so we are back to the Russian roulette. Other models gave her a 99% chance: they seem a bit off in retrospect, but one should check how they did state by state and how unlikely they concluded the actual outcome to be.&lt;/p&gt;
&lt;p&gt;Once anyone cooks up any risk model that spits out a probability for a given event, the work is not done yet. The interpretation of the outcome depends on how risky the situation is, and this could be somehow subjective. For example, I would advise against playing Russian roulette with one bullet, but I don’t mind leaving the house without the umbrella if there is a 17% chance of rain. Given the stakes in this election, I personally was freaking out when FiveThirtyEight gave Clinton less than a 70% chance of winning a few days before the election.&lt;/p&gt;
&lt;p&gt;To conclude, it is frustrating to see serious newspapers seemingly struggling to understand the statistical nature of a risk assessment. If all the polls were perfectly conducted (which they were not) and all the modelers had all the right assumptions (which seems unlikely), and we were told that Clinton had 90% chance of winning, this still would imply that there is a scenario in 10 that makes her lose. It is up to us then to decide if we are happy living with that or not.&lt;/p&gt;
&lt;p&gt;PS: for a more in depth analysis on some of these aspects, checkout the latest article on &lt;a href="http://fivethirtyeight.com/features/why-fivethirtyeight-gave-trump-a-better-chance-than-almost-anyone-else/"&gt;FiveThirtyEight&lt;/a&gt;.&lt;/p&gt;</summary><category term="data"></category><category term="social"></category></entry><entry><title>Taxi Ride Value</title><link href="/blog/taxi_rides/" rel="alternate"></link><updated>2016-05-20T22:30:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2016-05-20:blog/taxi_rides/</id><summary type="html">&lt;p&gt;Like many others this past year, I stumbled on the impressive set of &lt;a href="http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml"&gt;TLC Trip Data&lt;/a&gt; and took my turn at checking where the NYC cabs like to hang out. I planned to find the best spots for cabs to pick people up at different times of the day in orer to maximize their hourly income. I will explain here how and show you some plots, you can find code and more images in my &lt;a href="https://github.com/gobboph/nycabs"&gt;github repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These datasets are big. They encompass all the taxi rides from Jan 2009 to Dec 2015. For each month there are O(10^7) rides for which one gets pickup coordinates and datetime, dropoff coordinates and datetime, trip distance, passenger count, total amount paid split in categories, payment method and probably something else I am forgetting now. The files' size oscillates between 1.8-2.0 Gb per month.&lt;/p&gt;
&lt;p&gt;First of all, I downloaded Jan 2015 (literally the first file you see on the website) and here is a cool map of New York City drawn by scatter plotting pickup (in red) and dropoff (green) locations for the whole month.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/green.png" alt="NYC by cabs" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;If you played with this dataset (or with any dataset at all) you know that it needs some cleaning. There appear to be a staggering number of cabs picking people up at the North Pole or traveling at over 1000 miles/h on average. Some even arrive before leaving.&lt;/p&gt;
&lt;p&gt;These are easily taken care of, but what surprised me was that lots of people do not seem to tip: have I been an idiot all this time? The set of customers is divided clearly in tippers and non-tippers, which correspond almost 1 to 1 to card payers and cash payers. I am guessing that inserting the tip in the records when paid in cash is an extra mile that cab drivers are not willing to go for the sake of data collecting.&lt;/p&gt;
&lt;p&gt;I populated the tip column with a linear model based on the card payers and the data was pretty much good to go for further analysis.&lt;/p&gt;
&lt;p&gt;Now, how to assign value to a cab ride? Easiest answer: (total fare) / (ride duration). The problem with this first approximation is that it does not take into account the time that cabs spend finding new customers, i.e. not making money. Still I could not track every single cab to compute the non-paid time with this dataset.&lt;/p&gt;
&lt;p&gt;Luckily some &lt;a href="http://www.andresmh.com/nyctaxitrips/"&gt;old data&lt;/a&gt; has the info needed to track each single taxi. I dowloaded the first set that you find there, i.e. Jan 2013, and that is the base for all that follows.&lt;/p&gt;
&lt;p&gt;After combining and cleaneing this dataset as well, I computed the wait between two clients, here as average per hour of the day. Notice the gigantic variance even after I took care of cabs that are out of service.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/taxi_2013/wait_jan2013.png" alt="Cabs wait" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Going on, I defined the trip value as:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;trip value = (total fare) / (time waited + trip duration)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;and plotted it against hour of the day and day of the month (weekends and holidays and holidays in red).&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/taxi_2013/valueperhour_jan2013.png" alt="value per hour" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/taxi_2013/valueperday_jan2013.png" alt="value per day" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;The few cabs out at 5am are doing well (maybe because no one else is around) and then there is a peak after work. From the day of the month barplot we can easily infer that drunk folks like to take cabs after new year's eve celebrations. Also, the drivers seem to make increasingly more $/h as the week progresses.&lt;/p&gt;
&lt;p&gt;Finally, here is a panel with maps (you might want to enlarge it, but a blownup example is below). For each hour of the day the data is pixeled in location and the maps are colored according to the average trip value in each pixel. Pixels with too few cab pickups are discarded: there might be some very valuable trip, but still it is not advisable to drive a particular area if there are just a couple of pickups a month.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/taxi_2013/panel_jan2013.png" alt="value panel" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;As seen above, the middle of the day is not great, but downtown is consistently the best spot. One can also locate JFK and La Guardia airports: they are not necessarily the best spot in town, but they are a sure catch (as expected): the waiting involved probably takes down the trip value even if the total fare is high. Here is a blownup map for 9pm.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/taxi_2013/example_jan2013_21.png" alt="example map" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Lastly, I checked what parameters matter the most in determining the value of each trip (duration and total fare apart, of course). I trained a random forest and here is the result.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;img src="../../images/taxi_2013/features_jan2013.png" alt="features" style="width: 800px;"/&gt;&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;It turns out that cabs make more or less the same money whether it is holiday or not and what matters most is the hour of the day they are out working.&lt;/p&gt;
&lt;p&gt;Location is missing but I am planning to classify the rides by neighborhood. The panel above clearly shows that different neighborhoods will yield different trip values. The most straighforward endgame for this study would be an app that advises cab drivers on where to drive in order to maximize the dollars per hour, given features and location.&lt;/p&gt;
&lt;p&gt;Nevertheless, the obvious next step is to include more than one month worth of data. One month is pretty much all my 8Gb RAM macbook pro can take, but thankfully cloud computing is cheap and easily accessible.&lt;/p&gt;
&lt;p&gt;People have been using these data to implement &lt;a href="http://chriswhong.com/open-data/foil_nyc_taxi/"&gt;really cool visualizations&lt;/a&gt; and answer pressing questions like &lt;a href="http://toddwschneider.com/posts/analyzing-1-1-billion-nyc-taxi-and-uber-trips-with-a-vengeance/"&gt;is Die Hard a realistic movie?&lt;/a&gt;. Yet, I believe there is still a lot of useful projects that could be developed thanks to these datasets. Maximizing cab drivers income is a great possibility, but the real challenge would be to understand what changes our city could implement to make traffic more efficient and all our lives better.&lt;/p&gt;</summary><category term="data"></category><category term="social"></category></entry><entry><title>Election Words</title><link href="/blog/election_words/" rel="alternate"></link><updated>2014-08-04T12:50:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2014-08-04:blog/election_words/</id><summary type="html">&lt;p&gt;Ever wondered what are the best topic to talk about if you want to get elected in congress? And how do they change from state to state? I did and I tried to answer with &lt;a href="http://gobboph.github.io/election_words/"&gt;this&lt;/a&gt; little project of mine.&lt;/p&gt;
&lt;p&gt;I checked who are the folks tha get re-elected a lot in congress and what they talk about. To do that I used again some resources from the &lt;a href="https://sunlightfoundation.com/"&gt;Sunlight Foundation&lt;/a&gt; together with some wikipedia entry (I had to pin down all the people that have passed through congress in the past 20 years somehow).&lt;/p&gt;
&lt;p&gt;This analysis is totally preliminary and can be improved a lot, but it already shows something. First of all it is clear that one has to talk about their own regional problems (cities and boroughs are popular choices). Hovering around the map some topic of federal interest show up: obamacare, fracking, clean energy, iraq. On the other hand it is also clear that certain topics are regional: gambling in the south, HIV in big cities, fishing in the very North East.&lt;/p&gt;
&lt;p&gt;Most importantly though, can anybody explain to me the deal between South Carolina and Bulgaria?&lt;/p&gt;</summary><category term="programming"></category><category term="social"></category></entry><entry><title>Congress Words in Sunlight Foundation Blog</title><link href="/blog/congress_words_3/" rel="alternate"></link><updated>2014-06-21T12:45:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2014-06-21:blog/congress_words_3/</id><summary type="html">&lt;p&gt;Congress Words only works thanks to the &lt;a href="sunlightfoundation.com"&gt;Sunlinght Foundation&lt;/a&gt;, which provides the API's through their wonderful project &lt;a href="capitolwords.org"&gt;capitolwords.org&lt;/a&gt;. A while ago someone at the Sunlight Foundation saw my project and decided it was interesting enough to mention it in their official blog, so &lt;a href="http://sunlightfoundation.com/blog/2014/05/29/use-sunlights-apis-for-your-own-project/"&gt;here&lt;/a&gt; is the entry where they talk about me and Congress Words.&lt;/p&gt;
&lt;p&gt;It is extremely flattering that my little project caught their attention and made it to their blog! I think the foundation is doing an amazing job and I hope I will be able to contribute more in the future.&lt;/p&gt;</summary><category term="programming"></category><category term="social"></category></entry><entry><title>Congress Words Update</title><link href="/blog/conrgess_words_update/" rel="alternate"></link><updated>2014-04-26T20:00:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2014-04-26:blog/conrgess_words_update/</id><summary type="html">&lt;p&gt;A couple of days ago I decided to learn some JavaScript. I have been toying for a while with the idea of extending my little congress_words project to a website, so what better occasion?&lt;/p&gt;
&lt;p&gt;I rewrote the project so it runs entirely on JavaScript, using only jQuery and &lt;a href="http://gobboph.github.io/congress_words/"&gt;here&lt;/a&gt; is the result.&lt;/p&gt;
&lt;p&gt;The script is not too complicated, but it works well and, most importantly, I learned a lot while doing it; now I feel way more confident in my beaing able to learn something quickly. You can find the code at the github page of the &lt;a href="https://github.com/gobboph/congress_words/tree/gh-pages"&gt;project&lt;/a&gt; (in the master branch you can still see the python script).&lt;/p&gt;
&lt;p&gt;Play with &lt;a href="http://gobboph.github.io/congress_words/"&gt;it&lt;/a&gt; and let me know what you think.&lt;/p&gt;</summary><category term="programming"></category><category term="social"></category></entry><entry><title>Unwinding Inflation gets attention</title><link href="/blog/unwinding_inflation/" rel="alternate"></link><updated>2014-04-14T10:35:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2014-04-14:blog/unwinding_inflation/</id><summary type="html">&lt;p&gt;The data release of &lt;a href="http://bicepkeck.org/"&gt;BICEP2&lt;/a&gt; a couple of weeks ago caused much excitement in the physics community and justly so. First of all we were able to detect gravitational waves for the first time, albeit not directly. These gravitational waves were produced in a very early stage of our universe, as predicted by the inflationary paradigm, which in turn gets an important observational confirmation. Although we need confirmation from other experiments, the amount of gravitational waves that has been detected is much more than many people expected, thus ruling out the vast majority of models of inflation based on a microscopic theory of the very high energy (see String Theory).&lt;/p&gt;
&lt;p&gt;The good news is: Unwinding Inflation still stands! The model I developed together with my collaborators is one of the very few that might be able to explain inflation using String Theory. Lots of work still needs to be done on Unwinding to show that it can be embedded naturally into String Theory, but the road seem promising. This is very exciting for us and we are very much looking forward to future developements.&lt;/p&gt;</summary><category term="science"></category></entry><entry><title>Congress Words</title><link href="/blog/conrgess_words/" rel="alternate"></link><updated>2014-04-14T10:30:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2014-04-14:blog/conrgess_words/</id><summary type="html">&lt;p&gt;I spent a night last week having fun while working out this new project on github: &lt;a href="https://github.com/gobboph/congress_words"&gt;congress_words&lt;/a&gt;. Using the API's of &lt;a href="capitolwords.org"&gt;capitolwords.org&lt;/a&gt;, the scripts outputs a map of the US colored accordingly to how many times a given word or sentence of your choice has been pronunced by a representative of each state, of course normalized by number of state representatives.&lt;/p&gt;
&lt;p&gt;I find this to be a fantastic tool for procrastination and I plan to develop it into a website soon (it is important to be able to procrastinate no matter where we are). So come back to it soon!&lt;/p&gt;</summary><category term="programming"></category><category term="social"></category></entry><entry><title>First blog post</title><link href="/blog/first-post/" rel="alternate"></link><updated>2014-03-27T18:30:00-04:00</updated><author><name>Roberto Gobbetti</name></author><id>tag:,2014-03-27:blog/first-post/</id><summary type="html">&lt;p&gt;My personal website goes online! I have been toying with the idea of sitting down and building one for way too long, but finally here it is. This website is built with &lt;a href="http://docs.getpelican.com/en/3.3.0/"&gt;pelican&lt;/a&gt; and is online through my &lt;a href="https://github.com/gobboph"&gt;github page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I will use the blog to write about science, technology, politics, or really whatever I get interested into. Feel free to contact me.&lt;/p&gt;</summary><category term="miscellanea"></category></entry></feed>